<html>
    <head>
        <link rel="stylesheet" type="text/css" href="https://mharding.georgetown.domains/style.css"/>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

        <script type="text/javascript" src="https://mharding.georgetown.domains/portfolio_java.js"></script>
    </head>
    <body>
  
        <div class = "top_image_box">
            <img src="http://mharding.georgetown.domains/chesapeake_bay_img1.jpg" width = "1640"/>
        </div>
        
        <div id="mySidebar" class="sidebar">
            <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
            <a href="https://mharding.georgetown.domains/">Home</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/Introduction.html">Introduction</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/DataGathering.html">Data Gathering</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/DataCleaning.html">Data Cleaning</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/DataExploration.html">Exploring Data</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/Clustering.html">Clustering</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/ARMandNetworking.html">ARM & Networking</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/DecisionTrees.html">Decision Trees</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/NaiveBayes.html">NaiveBayes</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/SVM.html">SVM</a>
            <a href="https://mharding.georgetown.domains/ANLY_501/Conclusions.html">Conclusions</a>

        </div>
    
        <div id="main">
            <button class="openbtn" onclick="openNav()">&#9776;</button>
        </div>
        <div id="intro_title">
            Support Vector Machines
        </div>
        <div class = "svm">
            <div>
                <h2 class = "svm_head">
                    "Eyes on the Bay" Data 
                </h2>
            </div>
            <div>
                <div id = "data_gather_buttons" text-align = "left">

                        <a class="btn btn-outline-secondary btn-sm" href = "http://mharding.georgetown.domains/ANLY_501/DataCleaning/EOTB_Cleaned.csv" download="EOTB_Cleaned.csv" role = "button">Record Data</a>
                        
                        <a class="btn btn-outline-secondary btn-sm" href = "http://mharding.georgetown.domains/ANLY_501/SVM/SVM.Rmd" download="SVM.Rmd" role = "button">R Code</a>
                </div>
                    
            </div>
            <div class = "svm_txt_box">
                <p>
                    This data set has been used to study water quality throughout this analysis of the Chesapeake Bay. More specifically, it is being used to study dissolved oxygen levels and chlorophyll levels in the water. Eventually models were able to be developed using decision trees and naive Bayes to try to predict water quality behavior and understand when there may be low amounts of oxyge or harmful amounts of chlorophyll in the water. The naive Bayes models were more accurate than the decision tree models but both left something to be desired in terms of accuracy. To attempt to create a more accurate prediction from a model, another model that can be used is a support vector machine (SVM). This type of model is used to split a dataset into two groups by creating a plane in geometric space that optimizes the plane direction such that the closest point on either side of the plane is as far away from the plane as possible. SVMs can be very useful models because they have many parameters that can be tweaked. The most important of those parameters is the kernel which determines the shape of the plane. For example the kernel could be linear or a polynomial of degree 2, 3, 4, etc. Additionally, there is a cost parameter which allows the model to overlook certain points that fall in the margin or on the wrong side of the plane in order to create a better overall model. The cost is a parameter that needs a balance between giving the model some wiggle room while also not completely overfitting the model. The following analysis will attempt to choose the best kernel and cost parameters for each model corresponding to the dissolved oxygen and chlorophyll variables. As a note, for these models, the data needed to be subset in order to actually run the models in a reasonable amount of time. The data the model was trained on is the data spanning from 2010-2012. The model will later be tested on both a test set from this data as well as data spanning from 2016-2020. 
                </p>
                <p>
                    To begin creating a model for the dissolved oxygen variable the first thing that needs to be decided is which kernel is the best to use for this variable. To do this, an SVM function was run on the data multiple times using a different kernel each time and keeping all other parameters the same. Each of these models was then used to predict the labels on the test set and the accuracies of each model were measured to find which kernel was most accurate. The table of accuracies for each kernel can be seen in <i>Table 1</i>.
                </p>
            </div>
            <div>
                <figure class = "svm_img_box">
                    <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://mattharding23.github.io/501SVM/OX_acc_tab.html" height="290" width="100%"></iframe>
                    <figcaption>
                        Table 1: Prediction Accuracy of Dissolved Oxygen using SVM Models with Different Kernels
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    <i>Table 1</i> shows that the most accurate kernel in this case with all other parameters set to their defaults is the radial kernel. The next thing to do is to figure out a cost that gives the best accuracy without overfitting the model to the data. To do this, the model with the radial kernel was run over the same data with the cost of the model changing in each iteration. This was then plotted with the cost on the x-axis and the accuracy on the y-axis and was used as a type of elbow plot in order to determine the best plot. <i>Figure 1</i> below shows this plot. 
                </p>

            </div>
            
            
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/Accuracy_gain_ox.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 1: Cost vs accuracy plot for dissolved oxygen using radial kernel
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    The cost vs. accuracy plot shows that there is a large gain in accuracy over a small amount of increase in cost up to cost = 2.5 at which point the plot begins to get flatter. This indicates that the cost for this model should be set to 2.5. At this point, the model parameters are set so the model can be run on the data and tested with the test set. <i>Figure 2</i> shows the confusion matrix that was created for predictions made by the model. <i>Figure 3</i> is a classification plot that shows how the model labeled each point in the training set it was given vs what the label actually was and where it fell on the plot of the two most prominent variables in the dataset. 
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/ox_cm.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 2: Confusion matrix for dissolved oxygen using radial kernel
                    </figcaption>
                </figure>
            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/svm_class_plot_OX.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 3: SVM classification plot for dissolved oxygen using radial kernel
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    Immeadiately, the confusion matrix in <i>Figure 2</i> shows that this model is much more accurate than any of the previous models that have been used to predict dissolved oxygen levels. The label of interest, low oxygen levels, was predicted correctly at 92% while the overall accuracy of the model was a bit over 82%. This is a great accuracy rate for the model. Additionally, <i>Figure 3</i> gives a good visualization for how the model split the two groups with its kernel as well as the wiggle room the cost gave the model to allow for points to be on either side of the plane. Since this model was trained using only a subset of the data, it made sense to try and validate this model again with another subset of the data. The model was trained using data from 2010-2012 and the next test set used was from 2016-2020. The confusion matrix for this set of predictions can be seen below in <i>Figure 4</i>.
                </p>

            </div>
            <div>
                
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/ox_cm_pres.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 4: Confusion matrix of radial SVM model for dissolved oxygen tested on subset of data from 2016-2020
                    </figcaption>
                </figure>
            </div>
 
            
            <div class = "svm_txt_box">
                <p>
                    The confusion matrix in <i>Figure 4</i> shows a similar accuracy rate to that in <i>Figure 2</i> which indicates that this is a good model as it is able to use data from 2010-2012 to correctly predict the oxygen levels in the water at a rate of 83.5%. Knowing that this model worked well for the dissolved oxygen levels in this data set, the next thing to do is to try to model the chlorophyll levels in the same way. Using the same methods as described for dissolved oxygen, SVM models were run for the chlorophyll variable using many different kernels. THe table of accuracy rates for each kernel test can be seen in <i>Table 2</i>.
                </p>

            </div>
            <div>
                <figure class = "svm_img_box">
                    <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://mattharding23.github.io/501SVM/CL_acc_tab.html" height="290" width="100%"></iframe>
                    <figcaption>
                        Table 2: Prediction accuracy of chlorophyll using SVM models with different kernels
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    Interestingly, two of the kernels show very similar accuracy rate values - the radial kernel (again) and the quartic kernel which is a polynomial of degree 4. Because the accuracies were so close and because polynomials with higher degrees can tend to overfit a model to the data, the decision was made to test models using both kernels to determine which was ultimately a better model. The next step was to test the models using each of the two kernels over many different costs to try to find an optimal cost for each model. <i>Figures 5 & 6</i> show the cost vs. accuracy plots for each the quartic and radial kernels. 
                </p>

            </div>
            
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/Accuracy_gain_cl_quartic.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 5: Cost vs accuracy plot for chlorophyll using quartic kernel
                    </figcaption>
                </figure>
            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/Accuracy_gain_cl_radial.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 6: Cost vs accuracy plot for chlorophyll using radial kernel
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    The plot for the quartic kernel is very interesting in that the accuracy was actually better for the lowest possible cost. This is concerning, as the accuracy should get better with increased cost but ultimately, the cost of 0.1 was chosen for this model. The radial kernel model shows a sharp elbow where the cost is 2.5 so again, for the radial kernel, the cost will be set to 2.5. Next the models were trained for each kernel with their respected costs and then used to predict the categories of chlorophyll in the test set. <i>Figure 7</i> shows the confusion matrix for the model that uses the quartic kernel while <i>Figure 8</i> shows the classification plot for this model. 
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cl_cm_qrt.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 7: Confusion matrix for chlorophyll using quartic kernel
                    </figcaption>
                </figure>
            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/svm_class_plot_CL_qrt.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 8: SVM classification plot for chlorophyll using quartic kernel
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    The confusion matrix for the quartic kernel shows a high overall accuracy rate. However, that is skewed by the fact that there are many more test values of not harmful chlorophyll levels than there are for harmful levels. The harmful levels were only predicted correctly at a 60% rate which is a step back from the naive Bayes model created for this dataset. Additionally the classification plot shows that the model definitely classified many of the points incorrectly. Though this model did not perform well, it was still tested out on the 2016-2020 data set and that confusion matrix can be seen in <i>Figure 9</i>.
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cl_cm_pres_qrt.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 9: Confusion matrix of quartic SVM model for chlorophyll tested on subset of data from 2016-2020
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    The confusion matrix shows the model performed significantly worse when tested on data not within the range of dates it was trained on. Given this model did not predict the chlorophyll levels very well, the model with the radial kernel was tried next. <i>Figure 10</i> shows the confusion matrix created by the predicted values from the test set while <i>Figure 11</i> shows how the model classified the values in the training set. 
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cl_cm_rad.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 10: Confusion matrix for chlorophyll using radial kernel
                    </figcaption>
                </figure>
            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/svm_class_plot_CL_rad.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 11: SVM classification plot for chlorophyll using radial kernel
                    </figcaption>
                </figure>
            </div>

            <div class = "svm_txt_box">
                <p>
                    Though the overall accuracy is technically lower than the model that used the quartic kernel, this model is clearly better in that is predicts both categories at well above 80%. The overall accuracy does not mean as much because, as stated previously, the test set has many more values in one category than the other. Additionally, by looking at the classification plot, it can be seen the radial model classified the training set much better than the quartic model did. To validate this model further, it too was used to predict chlorophyll levels from the data in 2016-2020. The confusion matrix from these predictions can be seen in <i>Figure 12</i>.
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cl_cm_pres_rad.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 12: Confusion matrix of radial SVM model for chlorophyll tested on subset of data from 2017-2020
                    </figcaption>
                </figure>
            </div>
            <div class = "svm_txt_box">
                <p>
                    Disappointingly the model performed significantly worse when predicting this data than it did when predicting data from the same timeframe that it was trained from. 
                </p>
                <p>
                    Overall it can be concluded that the modelling of this dataset using support vector machines was relatively successful. Though SVMs were not able to train a model that ultimately accurately predicted chlorophyll levels in the water, it SVMs were able train a great model for predicting dissolved oxygen levels in the water which was the top priority for this data set. The low dissolved oxygen levels in the water were able to be predicted at a rate of over 90%. Moreover, the model was trained only using data from 2010-2012 and was still able to predict at the same accuracy rate for data spanning from 2016-2020. This means that the model created is extremely useful for predictions related to fidning low oxygen levels in the Chesapeake Bay and could be used to understand when regulations could be implemented to protect species living in the Bay. As for why the model that tried to predict chlorophyll levels did not work nearly as well there are a few possibilities. Firstly, the models could have been trained too specifically to the data they were given so when tested on new data that was different, the model struggled to predict correctly. Another possibility is that chlorophyll level patterns have changed from 2010-2012 to 2016-2020. This would make sense for the model that used the radial kernel to predict as it appeared to be a great model when tested on 2010-2012 data but did not work nearly as well for the data from 2016-2020.  
                </p>

            </div>
            
            
        </div>
        
        
        <div class = "svm">
            <div>
                <h2 class = "svm_head">
                    Twitter Data
                </h2>
            </div>
            <div>
                <div id = "data_gather_buttons" text-align = "left">

                         <a class="btn btn-outline-secondary btn-sm" href = "http://mharding.georgetown.domains/ANLY_501/DataCleaning/tweet_csvs.zip" download="tweets_csv.zip" role = "button">Download Tweets</a>
                        
                        <a class="btn btn-outline-secondary btn-sm" href = "http://mharding.georgetown.domains/ANLY_501/SVM/SVM.py" download="SVM.py" role = "button">Python Code</a>
                </div>
                    
            </div>
            <div class = "svm_txt_box">
                <p>
                    Similarly to the Eyes on the Bay data, the twitter data that has been studied through out this exploration of the Chesapeake Bay can be analyzed and predicted with an SVM model. Again though, to model text data, the data from the tweets needs to be in a numeric form. To do this they were run through a count vectorizer which places the number of times each word was used in each tweet into a numeric matrix. SVM models split data into two groups so in this model, the tweets with labels "river" and "environment" were used to train and test the models as they have been shown to be the most important labels to use to find tweets relating to the health of the Chesapeake Bay. After this, it was possible to run the data through a SVM model. As was mentioned in the section regarding the "Eyes on the Bay" data, SVM models have many parameters which can be optimized in order to build the best model. To begin this process, an SVM function was run on the data using many different kernels. Interestingly, all of the kernels except for a linear kernel classified all of the data into only one category. This clearly showed the linear kernel was the best option to use. Given the small set of data, the cost of the model also needed to be small. The cost was chosen to be 0.5. The data was then split into training and testing sets and run through the model. The predictiveness of the model was then tested by comparing the model to the labels of the test set. A confusion matrix of this process was created and can be seen in <i>Figure 13</i>
                    
                </p>

            </div>

            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cm_cv.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 13: Confusion Matrix of SVM Model on Count Vectorizer Data
                    </figcaption>
                </figure>
            </div>
            
            <div class = "svm_txt_box">
                <p>
                    Immeadiately, it can be seen that this model appears to work very well, only incorrectly predicting one tweet. However, it is possible that this accuracy could be in part due to the fact that there are not that many tweets to be working with. Unfortunately, there is not much that can be done to fix this as there just aren't that many tweets out there about this topic. However, more tweets could be gathered over time as they are put out and the model can then be updated to determine whether the model is really that accurate or not. But other visualization can be looked to manually view whether or not the model is doing a good job of separating the tweets. <i>Figure 14</i> shows a plot with the top features the model uses for predicting the tweets.
                    
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cv_features.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 14: Top Features from SVM model for count vectorizer data
                    </figcaption>
                </figure>
            </div>
 
            <div class = "svm_txt_box">
                <p>
                    By looking at the top features for each category, it can be seen that the top features for the envirnment category are in line with envirnmental topics while the top features for the river category are not nearly as related to river topics. 
                    
                </p>
                <p>
                    Another way to try and determine whether the accuracy on this model is correct is to use the same data but with normalized values which can be done using a TF-IDF vectorizer instead of a count vectorizer. This will likely put slightly different weights on each word and could change which kernel is best for the model as well as the model's predictions. Given the small dataset, the model may rely heavily on certain words that give it the illusion of accurate predictability when in reality a larger dataset would show it is much less accurate. When the TF-IDF data was run through an SVM function using many different kernels, the results were similar to that of the count vectorizer, deeming the linear kernel the best to use. The results were similar though slightly less accurate than the when the count vectorizer was used. This could show that the model may not be as robust as it looks for this dataset. The confusion matrix can be seen in <i>Figure 15</i> below. Additionally, <i>Figure 16</i> shows the top features that each category of the model uses. Though the confusion matrix shows it to be less accurate, the top features plot shows that both categories have many top features that are directly related to the topic the label suggests. This is a contrast and an improvement to the model created by the count vectorizer. 
                    
                </p>

            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/cm_tv.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 15: Confusion Matrix of SVM Model on TF-IDF vectorizer Data
                    </figcaption>
                </figure>
            </div>
            <div>
                <figure>
                    <img src="http://mharding.georgetown.domains/ANLY_501/SVM/tv_features.png" class = "svm_img_box" >
                    <figcaption>
                        Figure 16: Top Features from SVM model for TF-IDF vectorizer data
                    </figcaption>
                </figure>
            </div>
            
            <div class = "nb_txt_box">
                <p>
                    <i>Figure 13</i> and <i>Figure 15</i> show that a SVM model can very accurately categorize tweets based on the individual words inside of each tweet. While it is possible that the model may not be as great as it looks as was explained above, from the results that are there, it appears that it can categorize tweets at a very high accuracy rate. Additionally, the model created after normalizing the data also weights words directly related with the topic much better than the previous model. This type of model could be useful for companies and non-profits who are focused on the health of they Chesapeake Bay. They could possibly use it to select tweets that their account retweets or adds to the scroll on their website. Additionally, companies and politicians could use the model to filter tweets to understand what things people care about when it comes to the health of the Chesapeake Bay. As mentioned above, the model could definitely use some more data to become even better, but a model like this could definitely be useful to those with a stake in the health of the Bay. 
                    
                </p>

            </div>
            
            
        </div>
    </body>
</html>